# autoverse

- To evolve games for maximum complexity according to a search-based player agent, run `python evo_env.py`.
- To render the fittest environment-solution pairs found so far, run `python evo_env.py evaluate=True`
- To aggregate all unique environments that have been generated over the course of evolution, and record playtraces of their solutions as generated by search, run `python evo_env.py collect_elites=True`
- To imitation learn on these "oracle" playtraces, run `python train_il_player.py`.

## Interactive environment:
```
python human_env.py game=lava_maze window_shape=[1000,1000]
```
Use the left and right arrow keys to rotate the agent, and `q` to place a `force` tile in front of the agent, which will
move it forward where appropriate. The game is defined in `games/lava_maze.py`.

## Profile environment:
```
python profile_env.py game=lava_maze
```
This will initialize a level in the give game, and take random actions. It will then print the FPS of `reset()` and `step()`.

## Render solution:
```
python render_solution.py game=lava_maze
```
This will initialize a random level in the given game, and search for some number of iterations for a solution. It will
then save a video of the solution.

## Render in blender (deprecated)
To render in blender:
```bash
blender render_scene.blend --python enjoy_blender.py
```

# Notes

Because jax allocates gpu memory in advance, making `total_timesteps` too large will cause an out-of-memory error.
However, complete jobs can be resumed with increased `total_timesteps` where jax will only allocate the difference between 
completed and pending timesteps in advance.

# TODO:

- [] Make search more efficient, taking advantage of jax parallelism somehow (since right now we take one step in one environment at a time, then hash the state to see if it's visited; would it be advantageous to step a huge number of mutants at once, then hash the resultant states---potentially distributing this process across CPUs? Or is there some clever way to hash the states in jax on the GPU?)
- [] When the search cap is increased, maybe we want to pick up where we left off searching in the current elite environments? It's only fair. We should also hash mutant env params against existing elites, if we're not already
