# autoverse

- To evolve games for maximum complexity according to a search-based player agent, run `python evo_env.py`.
- To render the fittest environment-solution pairs found so far, run `python evo_env.py evaluate=True`
- To aggregate all unique environments that have been generated over the course of evolution, and record playtraces of their solutions as generated by search, run `python evo_env.py collect_elites=True`
- To imitation learn on these "oracle" playtraces, run `python train_il_player.py`.

## Interactive environment:
```
python human_env.py game=lava_maze window_shape=[1000,1000]
```
Use the left and right arrow keys to rotate the agent, and `q` to place a `force` tile in front of the agent, which will
move it forward where appropriate. The game is defined in `games/lava_maze.py`.

## Profile environment:
```
python profile_env.py game=lava_maze
```
This will initialize a level in the give game, and take random actions. It will then print the FPS of `reset()` and `step()`.

## Render solution:
```
python render_solution.py game=lava_maze
```
This will initialize a random level in the given game, and search for some number of iterations for a solution. It will
then save a video of the solution.

## Render in blender (deprecated)
To render in blender:
```bash
blender render_scene.blend --python enjoy_blender.py
```

# Notes

Because jax allocates gpu memory in advance, making `total_timesteps` too large will cause an out-of-memory error.
However, complete jobs can be resumed with increased `total_timesteps` where jax will only allocate the difference between 
completed and pending timesteps in advance.
